{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":653195,"sourceType":"datasetVersion","datasetId":325566},{"sourceId":9873876,"sourceType":"datasetVersion","datasetId":6061668},{"sourceId":9879818,"sourceType":"datasetVersion","datasetId":6018167}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/alexalen03/2000-data-emo?scriptVersionId=206704660\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/cremad'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-12T05:45:33.578657Z","iopub.execute_input":"2024-11-12T05:45:33.579519Z","iopub.status.idle":"2024-11-12T05:45:40.516526Z","shell.execute_reply.started":"2024-11-12T05:45:33.57945Z","shell.execute_reply":"2024-11-12T05:45:40.515105Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport numpy as np\nimport pandas as pd\nfrom sklearn import svm\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom skimage.io import imread\nfrom skimage.transform import resize\nfrom tqdm import tqdm\n\n# Directory paths\ndataset_dir = 'dataset'\ncancer_dir = os.path.join(dataset_dir, 'cancer_skin')\nnormal_dir = os.path.join(dataset_dir, 'normal_skin')\n\n# Load and preprocess images\ndef load_images_from_folder(folder, label, img_size=(64, 64)):\n    images = []\n    labels = []\n    for filename in os.listdir(folder):\n        img_path = os.path.join(folder, filename)\n        img = imread(img_path)\n        img = resize(img, img_size).flatten()  # Resize and flatten image\n        images.append(img)\n        labels.append(label)\n    return images, labels\n\n# Load cancer and normal skin images\ncancer_images, cancer_labels = load_images_from_folder(cancer_dir, label=1)\nnormal_images, normal_labels = load_images_from_folder(normal_dir, label=0)\n\n# Combine the datasets\nX = np.array(cancer_images + normal_images)\ny = np.array(cancer_labels + normal_labels)\n\n# Scale the features\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\n# Define cross-validation and Train-on-Complete-Test-on-Complete setups\nk_values = [2, 4, 5, 10]\nresults = []\n\ndef evaluate_model(y_true, y_pred, y_proba):\n    metrics = {\n        'accuracy': accuracy_score(y_true, y_pred),\n        'precision': precision_score(y_true, y_pred),\n        'recall': recall_score(y_true, y_pred),\n        'auc': roc_auc_score(y_true, y_proba),\n    }\n    return metrics\n\n# Perform k-fold cross-validation for each k in k_values\nfor k in tqdm(k_values, desc=\"Processing different k values\"):\n    skf = StratifiedKFold(n_splits=k)\n    fold_results = []\n\n    # For each fold in k-fold cross-validation\n    for train_index, test_index in tqdm(skf.split(X, y), desc=f\"Folds for k={k}\", leave=False):\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n        \n        # Train SVM model\n        model = svm.SVC(kernel='rbf', C=1, gamma='scale', probability=True)\n        model.fit(X_train, y_train)\n        \n        # Predict and evaluate\n        y_pred = model.predict(X_test)\n        y_proba = model.predict_proba(X_test)[:, 1]  # Get probability scores for AUC\n        metrics = evaluate_model(y_test, y_pred, y_proba)\n        fold_results.append(metrics)\n    \n    # Average metrics over folds\n    avg_metrics = {metric: np.mean([f[metric] for f in fold_results]) for metric in fold_results[0]}\n    avg_metrics['fold'] = f'k={k}'\n    results.append(avg_metrics)\n\n# Train-on-Complete and Test-on-Complete (TT)\nmodel_tt = svm.SVC(kernel='rbf', C=1, gamma='scale', probability=True)\nmodel_tt.fit(X, y)\ny_pred_tt = model_tt.predict(X)\ny_proba_tt = model_tt.predict_proba(X)[:, 1]\ntt_metrics = evaluate_model(y, y_pred_tt, y_proba_tt)\ntt_metrics['fold'] = 'Train on Complete and Test on Complete (TT)'\nresults.append(tt_metrics)\n\n# Save results to Excel\nresults_df = pd.DataFrame(results)\nresults_df.to_excel(\"svm_metrics_results.xlsx\", index=False)\nprint(\"Metrics saved to svm_metrics_results.xlsx\")\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/ins-cycle-pth/checkpoint_epoch_200.pth'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T05:45:40.518998Z","iopub.execute_input":"2024-11-12T05:45:40.519932Z","iopub.status.idle":"2024-11-12T05:45:40.529014Z","shell.execute_reply.started":"2024-11-12T05:45:40.519875Z","shell.execute_reply":"2024-11-12T05:45:40.528186Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/iemocap-audios/Neutral'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T05:45:40.530236Z","iopub.execute_input":"2024-11-12T05:45:40.530773Z","iopub.status.idle":"2024-11-12T05:45:41.37811Z","shell.execute_reply.started":"2024-11-12T05:45:40.530736Z","shell.execute_reply":"2024-11-12T05:45:41.376981Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/iemocap-audios/Anger'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T05:45:41.381071Z","iopub.execute_input":"2024-11-12T05:45:41.382027Z","iopub.status.idle":"2024-11-12T05:45:42.048511Z","shell.execute_reply.started":"2024-11-12T05:45:41.381973Z","shell.execute_reply":"2024-11-12T05:45:42.047448Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\n\n# Define source and target directories\nsource_folder = '/kaggle/input/cremad/AudioWAV'\ntarget_folder = 'data'\n\n# Create target subfolders if they don't exist\nos.makedirs(os.path.join(target_folder, 'NEU'), exist_ok=True)\nos.makedirs(os.path.join(target_folder, 'ANG'), exist_ok=True)\n\n# Iterate over all files in the source folder\nfor file_name in os.listdir(source_folder):\n    # Check if the file is a .wav file\n    if file_name.endswith('.wav'):\n        # Move files with \"NEU\" in the filename to NEU folder\n        if '_NEU_' in file_name:\n            shutil.copy(os.path.join(source_folder, file_name), os.path.join(target_folder, 'NEU', file_name))\n        # Move files with \"ANG\" in the filename to ANG folder\n        elif '_ANG_' in file_name:\n            shutil.copy(os.path.join(source_folder, file_name), os.path.join(target_folder, 'ANG', file_name))\n\nprint(\"Files have been organized into 'data/NEU' and 'data/ANG'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T05:45:42.049867Z","iopub.execute_input":"2024-11-12T05:45:42.050255Z","iopub.status.idle":"2024-11-12T05:45:56.215331Z","shell.execute_reply.started":"2024-11-12T05:45:42.050212Z","shell.execute_reply":"2024-11-12T05:45:56.214242Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\nimport os\n\ndef copy_files(src_dest_pairs):\n    for src_folder, dest_folder in src_dest_pairs:\n        # Ensure the destination folder exists\n        os.makedirs(dest_folder, exist_ok=True)\n        \n        # Copy each file in the source folder to the destination folder\n        for filename in os.listdir(src_folder):\n            src_path = os.path.join(src_folder, filename)\n            dest_path = os.path.join(dest_folder, filename)\n            \n            # Check if it is a file (not a folder)\n            if os.path.isfile(src_path):\n                shutil.copy(src_path, dest_path)\n                print(f\"Copied: {src_path} -> {dest_path}\")\n\n# Example usage:\nsrc_dest_pairs = [\n    (\"/kaggle/input/iemocap-audios/Anger\", \"/kaggle/working/data/ANG\"),\n    (\"/kaggle/input/iemocap-audios/Neutral\", \"/kaggle/working/data/NEU\"),\n    # Add more source-destination pairs as needed\n]\n\ncopy_files(src_dest_pairs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T05:45:56.216548Z","iopub.execute_input":"2024-11-12T05:45:56.216933Z","iopub.status.idle":"2024-11-12T05:46:13.814091Z","shell.execute_reply.started":"2024-11-12T05:45:56.216876Z","shell.execute_reply":"2024-11-12T05:46:13.813126Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\ndef count_files(folder_path):\n    # List all files in the folder and count only those that are files\n    num_files = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n    return num_files\n\n# Example usage:\nfolder_path = \"/kaggle/working/data/NEU\"\nprint(f\"Number of files in '{folder_path}': {count_files(folder_path)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T05:46:13.815153Z","iopub.execute_input":"2024-11-12T05:46:13.815503Z","iopub.status.idle":"2024-11-12T05:46:13.847008Z","shell.execute_reply.started":"2024-11-12T05:46:13.815441Z","shell.execute_reply":"2024-11-12T05:46:13.846027Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\ndef count_files(folder_path):\n    # List all files in the folder and count only those that are files\n    num_files = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n    return num_files\n\n# Example usage:\nfolder_path = \"/kaggle/working/data/ANG\"\nprint(f\"Number of files in '{folder_path}': {count_files(folder_path)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T05:46:13.848197Z","iopub.execute_input":"2024-11-12T05:46:13.84852Z","iopub.status.idle":"2024-11-12T05:46:13.875739Z","shell.execute_reply.started":"2024-11-12T05:46:13.848457Z","shell.execute_reply":"2024-11-12T05:46:13.874718Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchaudio\nimport os\nimport numpy as np\nfrom tqdm import tqdm\n\n# Define the Generator\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n            nn.InstanceNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.InstanceNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.InstanceNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1),\n            nn.InstanceNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n            nn.InstanceNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1),\n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        return self.model(x)\n\n# Define the Discriminator\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n            nn.InstanceNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n            nn.InstanceNorm2d(256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),\n            nn.InstanceNorm2d(512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.AdaptiveAvgPool2d(1),\n            nn.Conv2d(512, 1, kernel_size=1)\n        )\n\n    def forward(self, x):\n        return self.model(x).view(-1)\n\n# Define the VoiceDataset\nclass VoiceDataset(Dataset):\n    def __init__(self, root_dir, n_mels=128, n_fft=2048, hop_length=512, fixed_length=128):\n        self.root_dir = root_dir\n        self.neu_files = os.listdir(os.path.join(root_dir, 'NEU'))\n        self.sad_files = os.listdir(os.path.join(root_dir, 'ANG'))\n        self.length = min(len(self.neu_files), len(self.sad_files))\n        self.mel_transform = torchaudio.transforms.MelSpectrogram(\n            n_mels=n_mels, n_fft=n_fft, hop_length=hop_length\n        )\n        self.fixed_length = fixed_length\n\n    def __len__(self):\n        return self.length\n\n    def pad_or_truncate(self, mel):\n        if mel.size(2) < self.fixed_length:\n            # Pad with zeros to the right\n            padding = self.fixed_length - mel.size(2)\n            mel = torch.nn.functional.pad(mel, (0, padding), \"constant\", 0)\n        elif mel.size(2) > self.fixed_length:\n            # Truncate to the fixed length\n            mel = mel[:, :, :self.fixed_length]\n        return mel\n\n    def __getitem__(self, idx):\n        neu_path = os.path.join(self.root_dir, 'NEU', self.neu_files[idx])\n        sad_path = os.path.join(self.root_dir, 'ANG', self.sad_files[idx])\n\n        neu_audio, _ = torchaudio.load(neu_path)\n        sad_audio, _ = torchaudio.load(sad_path)\n\n        # Ensure mono audio\n        neu_audio = neu_audio.mean(dim=0, keepdim=True)\n        sad_audio = sad_audio.mean(dim=0, keepdim=True)\n\n        # Convert to mel spectrograms\n        neu_mel = self.mel_transform(neu_audio)\n        sad_mel = self.mel_transform(sad_audio)\n\n        # Normalize\n        neu_mel = (neu_mel - neu_mel.mean()) / neu_mel.std()\n        sad_mel = (sad_mel - sad_mel.mean()) / sad_mel.std()\n\n        # Pad or truncate to fixed length\n        neu_mel = self.pad_or_truncate(neu_mel)\n        sad_mel = self.pad_or_truncate(sad_mel)\n\n        return neu_mel, sad_mel\n\n# Helper function for weight initialization\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)\n\n# Function to save checkpoints\ndef save_checkpoint(epoch, G_neu2sad, G_sad2neu, D_neu, D_sad, \n                    optimizer_G, optimizer_D_neu, optimizer_D_sad, filename=\"checkpoint.pth\"):\n    torch.save({\n        'epoch': epoch,\n        'G_neu2sad_state_dict': G_neu2sad.state_dict(),\n        'G_sad2neu_state_dict': G_sad2neu.state_dict(),\n        'D_neu_state_dict': D_neu.state_dict(),\n        'D_sad_state_dict': D_sad.state_dict(),\n        'optimizer_G_state_dict': optimizer_G.state_dict(),\n        'optimizer_D_neu_state_dict': optimizer_D_neu.state_dict(),\n        'optimizer_D_sad_state_dict': optimizer_D_sad.state_dict(),\n    }, filename)\n\n# Training function\ndef train(dataloader, num_epochs=300, start_epoch=0, checkpoint_path=None):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    # Initialize networks\n    G_neu2sad = Generator().to(device)\n    G_sad2neu = Generator().to(device)\n    D_neu = Discriminator().to(device)\n    D_sad = Discriminator().to(device)\n\n    G_neu2sad.apply(weights_init)\n    G_sad2neu.apply(weights_init)\n    D_neu.apply(weights_init)\n    D_sad.apply(weights_init)\n\n    # Loss functions\n    criterion_cycle = nn.L1Loss()\n\n    # Optimizers\n    optimizer_G = optim.Adam(list(G_neu2sad.parameters()) + list(G_sad2neu.parameters()), lr=0.0001, betas=(0.5, 0.9))\n    optimizer_D_neu = optim.Adam(D_neu.parameters(), lr=0.0001, betas=(0.5, 0.9))\n    optimizer_D_sad = optim.Adam(D_sad.parameters(), lr=0.0001, betas=(0.5, 0.9))\n\n    # Load checkpoint if provided\n    if checkpoint_path:\n        checkpoint = torch.load(checkpoint_path)\n        G_neu2sad.load_state_dict(checkpoint['G_neu2sad_state_dict'])\n        G_sad2neu.load_state_dict(checkpoint['G_sad2neu_state_dict'])\n        D_neu.load_state_dict(checkpoint['D_neu_state_dict'])\n        D_sad.load_state_dict(checkpoint['D_sad_state_dict'])\n        optimizer_G.load_state_dict(checkpoint['optimizer_G_state_dict'])\n        optimizer_D_neu.load_state_dict(checkpoint['optimizer_D_neu_state_dict'])\n        optimizer_D_sad.load_state_dict(checkpoint['optimizer_D_sad_state_dict'])\n        start_epoch = checkpoint['epoch']\n\n    for epoch in range(start_epoch, num_epochs):\n        for i, (neu, sad) in enumerate(tqdm(dataloader)):\n            neu = neu.to(device)\n            sad = sad.to(device)\n\n            # Train Discriminators\n            for _ in range(5):  # Update discriminators more frequently\n                optimizer_D_neu.zero_grad()\n                optimizer_D_sad.zero_grad()\n\n                # Discriminator Neu\n                loss_D_neu_real = -torch.mean(D_neu(neu))\n                fake_neu = G_sad2neu(sad).detach()\n                loss_D_neu_fake = torch.mean(D_neu(fake_neu))\n                loss_D_neu = loss_D_neu_real + loss_D_neu_fake\n                loss_D_neu.backward()\n                optimizer_D_neu.step()\n\n                # Discriminator Sad\n                loss_D_sad_real = -torch.mean(D_sad(sad))\n                fake_sad = G_neu2sad(neu).detach()\n                loss_D_sad_fake = torch.mean(D_sad(fake_sad))\n                loss_D_sad = loss_D_sad_real + loss_D_sad_fake\n                loss_D_sad.backward()\n                optimizer_D_sad.step()\n\n                # Clip weights of discriminators\n                for d in [D_neu, D_sad]:\n                    for p in d.parameters():\n                        p.data.clamp_(-0.01, 0.01)\n\n            # Train Generators\n            optimizer_G.zero_grad()\n\n            # GAN loss\n            fake_sad = G_neu2sad(neu)\n            loss_GAN_neu2sad = -torch.mean(D_sad(fake_sad))\n\n            fake_neu = G_sad2neu(sad)\n            loss_GAN_sad2neu = -torch.mean(D_neu(fake_neu))\n\n            # Cycle loss\n            recovered_neu = G_sad2neu(fake_sad)\n            loss_cycle_neu = criterion_cycle(recovered_neu, neu)\n\n            recovered_sad = G_neu2sad(fake_neu)\n            loss_cycle_sad = criterion_cycle(recovered_sad, sad)\n\n            # Total generator loss\n            loss_G = loss_GAN_neu2sad + loss_GAN_sad2neu + 10 * (loss_cycle_neu + loss_cycle_sad)\n            loss_G.backward()\n            optimizer_G.step()\n\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss G: {loss_G.item():.4f}, Loss D_neu: {loss_D_neu.item():.4f}, Loss D_sad: {loss_D_sad.item():.4f}\")\n\n        # Save checkpoint every 100 epochs\n        if (epoch + 1) % 100 == 0:\n            save_checkpoint(epoch + 1, G_neu2sad, G_sad2neu, D_neu, D_sad, \n                            optimizer_G, optimizer_D_neu, optimizer_D_sad, f\"checkpoint_epoch_{epoch+1}.pth\")\n        elif (epoch + 1) == 465:\n            save_checkpoint(epoch + 1, G_neu2sad, G_sad2neu, D_neu, D_sad, \n                            optimizer_G, optimizer_D_neu, optimizer_D_sad, f\"checkpoint_epoch_{epoch+1}.pth\")\n\n    return G_neu2sad, G_sad2neu\n\n# Main execution\nif __name__ == \"__main__\":\n    # Set up the dataset and dataloader\n    dataset = VoiceDataset(\"/kaggle/working/data\")\n    dataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=4)\n\n    # Train the model, starting from epoch 0\n    start_epoch = 200\n    checkpoint_path = \"/kaggle/input/ins-cycle-pth/checkpoint_epoch_200.pth\"  # Set to None since we're starting from scratch\n    num_epochs = 465  # Total number of epochs to train\n\n    G_neu2sad, G_sad2neu = train(dataloader, num_epochs=num_epochs, start_epoch=start_epoch, checkpoint_path=checkpoint_path)\n\n    # Save the final trained models\n    torch.save(G_neu2sad.state_dict(), \"G_neu2sad_final.pth\")\n    torch.save(G_sad2neu.state_dict(), \"G_sad2neu_final.pth\")\n\n    print(\"Training complete. Final models saved.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T05:46:13.877171Z","iopub.execute_input":"2024-11-12T05:46:13.877508Z","iopub.status.idle":"2024-11-12T05:50:40.156815Z","shell.execute_reply.started":"2024-11-12T05:46:13.87745Z","shell.execute_reply":"2024-11-12T05:50:40.155088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}